{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzaFKJvYL-Lt",
        "outputId": "1b108138-ea40-408b-b308-a60c4513fa55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 74 Sep 20 13:26 kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!ls -lha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle #Create the directory"
      ],
      "metadata": {
        "id": "AHdae63MMvMG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "URAkScqlMyBB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download sumairaziz/vibration-faults-dataset-for-rotating-machines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2StnVZrM_oS",
        "outputId": "c50f3b2b-144d-4407-ae20-007cc6fd1aee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/sumairaziz/vibration-faults-dataset-for-rotating-machines\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading vibration-faults-dataset-for-rotating-machines.zip to /content\n",
            "  0% 0.00/18.6M [00:00<?, ?B/s]\n",
            "100% 18.6M/18.6M [00:00<00:00, 596MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/vibration-faults-dataset-for-rotating-machines.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AlFHPyBNnip",
        "outputId": "41bb4a7f-4c1a-44b8-efd6-89a5b70f7494"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/vibration-faults-dataset-for-rotating-machines.zip\n",
            "  inflating: Faulty/F1.mat           \n",
            "  inflating: Faulty/F10.mat          \n",
            "  inflating: Faulty/F100.mat         \n",
            "  inflating: Faulty/F101.mat         \n",
            "  inflating: Faulty/F102.mat         \n",
            "  inflating: Faulty/F103.mat         \n",
            "  inflating: Faulty/F104.mat         \n",
            "  inflating: Faulty/F105.mat         \n",
            "  inflating: Faulty/F106.mat         \n",
            "  inflating: Faulty/F107.mat         \n",
            "  inflating: Faulty/F108.mat         \n",
            "  inflating: Faulty/F109.mat         \n",
            "  inflating: Faulty/F11.mat          \n",
            "  inflating: Faulty/F110.mat         \n",
            "  inflating: Faulty/F111.mat         \n",
            "  inflating: Faulty/F112.mat         \n",
            "  inflating: Faulty/F113.mat         \n",
            "  inflating: Faulty/F114.mat         \n",
            "  inflating: Faulty/F115.mat         \n",
            "  inflating: Faulty/F116.mat         \n",
            "  inflating: Faulty/F117.mat         \n",
            "  inflating: Faulty/F12.mat          \n",
            "  inflating: Faulty/F13.mat          \n",
            "  inflating: Faulty/F14.mat          \n",
            "  inflating: Faulty/F15.mat          \n",
            "  inflating: Faulty/F16.mat          \n",
            "  inflating: Faulty/F17.mat          \n",
            "  inflating: Faulty/F18.mat          \n",
            "  inflating: Faulty/F19.mat          \n",
            "  inflating: Faulty/F2.mat           \n",
            "  inflating: Faulty/F20.mat          \n",
            "  inflating: Faulty/F21.mat          \n",
            "  inflating: Faulty/F22.mat          \n",
            "  inflating: Faulty/F23.mat          \n",
            "  inflating: Faulty/F24.mat          \n",
            "  inflating: Faulty/F25.mat          \n",
            "  inflating: Faulty/F26.mat          \n",
            "  inflating: Faulty/F27.mat          \n",
            "  inflating: Faulty/F28.mat          \n",
            "  inflating: Faulty/F29.mat          \n",
            "  inflating: Faulty/F3.mat           \n",
            "  inflating: Faulty/F30.mat          \n",
            "  inflating: Faulty/F31.mat          \n",
            "  inflating: Faulty/F32.mat          \n",
            "  inflating: Faulty/F33.mat          \n",
            "  inflating: Faulty/F34.mat          \n",
            "  inflating: Faulty/F35.mat          \n",
            "  inflating: Faulty/F36.mat          \n",
            "  inflating: Faulty/F37.mat          \n",
            "  inflating: Faulty/F38.mat          \n",
            "  inflating: Faulty/F39.mat          \n",
            "  inflating: Faulty/F4.mat           \n",
            "  inflating: Faulty/F40.mat          \n",
            "  inflating: Faulty/F41.mat          \n",
            "  inflating: Faulty/F42.mat          \n",
            "  inflating: Faulty/F43.mat          \n",
            "  inflating: Faulty/F44.mat          \n",
            "  inflating: Faulty/F45.mat          \n",
            "  inflating: Faulty/F46.mat          \n",
            "  inflating: Faulty/F47.mat          \n",
            "  inflating: Faulty/F48.mat          \n",
            "  inflating: Faulty/F49.mat          \n",
            "  inflating: Faulty/F5.mat           \n",
            "  inflating: Faulty/F50.mat          \n",
            "  inflating: Faulty/F51.mat          \n",
            "  inflating: Faulty/F52.mat          \n",
            "  inflating: Faulty/F53.mat          \n",
            "  inflating: Faulty/F54.mat          \n",
            "  inflating: Faulty/F55.mat          \n",
            "  inflating: Faulty/F56.mat          \n",
            "  inflating: Faulty/F57.mat          \n",
            "  inflating: Faulty/F58.mat          \n",
            "  inflating: Faulty/F59.mat          \n",
            "  inflating: Faulty/F6.mat           \n",
            "  inflating: Faulty/F60.mat          \n",
            "  inflating: Faulty/F61.mat          \n",
            "  inflating: Faulty/F62.mat          \n",
            "  inflating: Faulty/F63.mat          \n",
            "  inflating: Faulty/F64.mat          \n",
            "  inflating: Faulty/F65.mat          \n",
            "  inflating: Faulty/F66.mat          \n",
            "  inflating: Faulty/F67.mat          \n",
            "  inflating: Faulty/F68.mat          \n",
            "  inflating: Faulty/F69.mat          \n",
            "  inflating: Faulty/F7.mat           \n",
            "  inflating: Faulty/F70.mat          \n",
            "  inflating: Faulty/F71.mat          \n",
            "  inflating: Faulty/F72.mat          \n",
            "  inflating: Faulty/F73.mat          \n",
            "  inflating: Faulty/F74.mat          \n",
            "  inflating: Faulty/F75.mat          \n",
            "  inflating: Faulty/F76.mat          \n",
            "  inflating: Faulty/F77.mat          \n",
            "  inflating: Faulty/F78.mat          \n",
            "  inflating: Faulty/F79.mat          \n",
            "  inflating: Faulty/F8.mat           \n",
            "  inflating: Faulty/F80.mat          \n",
            "  inflating: Faulty/F81.mat          \n",
            "  inflating: Faulty/F82.mat          \n",
            "  inflating: Faulty/F83.mat          \n",
            "  inflating: Faulty/F84.mat          \n",
            "  inflating: Faulty/F85.mat          \n",
            "  inflating: Faulty/F86.mat          \n",
            "  inflating: Faulty/F87.mat          \n",
            "  inflating: Faulty/F88.mat          \n",
            "  inflating: Faulty/F89.mat          \n",
            "  inflating: Faulty/F9.mat           \n",
            "  inflating: Faulty/F90.mat          \n",
            "  inflating: Faulty/F91.mat          \n",
            "  inflating: Faulty/F92.mat          \n",
            "  inflating: Faulty/F93.mat          \n",
            "  inflating: Faulty/F94.mat          \n",
            "  inflating: Faulty/F95.mat          \n",
            "  inflating: Faulty/F96.mat          \n",
            "  inflating: Faulty/F97.mat          \n",
            "  inflating: Faulty/F98.mat          \n",
            "  inflating: Faulty/F99.mat          \n",
            "  inflating: Healthy/H1.mat          \n",
            "  inflating: Healthy/H10.mat         \n",
            "  inflating: Healthy/H100.mat        \n",
            "  inflating: Healthy/H101.mat        \n",
            "  inflating: Healthy/H102.mat        \n",
            "  inflating: Healthy/H103.mat        \n",
            "  inflating: Healthy/H11.mat         \n",
            "  inflating: Healthy/H12.mat         \n",
            "  inflating: Healthy/H13.mat         \n",
            "  inflating: Healthy/H14.mat         \n",
            "  inflating: Healthy/H15.mat         \n",
            "  inflating: Healthy/H16.mat         \n",
            "  inflating: Healthy/H17.mat         \n",
            "  inflating: Healthy/H18.mat         \n",
            "  inflating: Healthy/H19.mat         \n",
            "  inflating: Healthy/H2.mat          \n",
            "  inflating: Healthy/H20.mat         \n",
            "  inflating: Healthy/H21.mat         \n",
            "  inflating: Healthy/H22.mat         \n",
            "  inflating: Healthy/H23.mat         \n",
            "  inflating: Healthy/H24.mat         \n",
            "  inflating: Healthy/H25.mat         \n",
            "  inflating: Healthy/H26.mat         \n",
            "  inflating: Healthy/H27.mat         \n",
            "  inflating: Healthy/H28.mat         \n",
            "  inflating: Healthy/H29.mat         \n",
            "  inflating: Healthy/H3.mat          \n",
            "  inflating: Healthy/H30.mat         \n",
            "  inflating: Healthy/H31.mat         \n",
            "  inflating: Healthy/H32.mat         \n",
            "  inflating: Healthy/H33.mat         \n",
            "  inflating: Healthy/H34.mat         \n",
            "  inflating: Healthy/H35.mat         \n",
            "  inflating: Healthy/H36.mat         \n",
            "  inflating: Healthy/H37.mat         \n",
            "  inflating: Healthy/H38.mat         \n",
            "  inflating: Healthy/H39.mat         \n",
            "  inflating: Healthy/H4.mat          \n",
            "  inflating: Healthy/H40.mat         \n",
            "  inflating: Healthy/H41.mat         \n",
            "  inflating: Healthy/H42.mat         \n",
            "  inflating: Healthy/H43.mat         \n",
            "  inflating: Healthy/H44.mat         \n",
            "  inflating: Healthy/H45.mat         \n",
            "  inflating: Healthy/H46.mat         \n",
            "  inflating: Healthy/H47.mat         \n",
            "  inflating: Healthy/H48.mat         \n",
            "  inflating: Healthy/H49.mat         \n",
            "  inflating: Healthy/H5.mat          \n",
            "  inflating: Healthy/H50.mat         \n",
            "  inflating: Healthy/H51.mat         \n",
            "  inflating: Healthy/H52.mat         \n",
            "  inflating: Healthy/H53.mat         \n",
            "  inflating: Healthy/H54.mat         \n",
            "  inflating: Healthy/H55.mat         \n",
            "  inflating: Healthy/H56.mat         \n",
            "  inflating: Healthy/H57.mat         \n",
            "  inflating: Healthy/H58.mat         \n",
            "  inflating: Healthy/H59.mat         \n",
            "  inflating: Healthy/H6.mat          \n",
            "  inflating: Healthy/H60.mat         \n",
            "  inflating: Healthy/H61.mat         \n",
            "  inflating: Healthy/H62.mat         \n",
            "  inflating: Healthy/H63.mat         \n",
            "  inflating: Healthy/H64.mat         \n",
            "  inflating: Healthy/H65.mat         \n",
            "  inflating: Healthy/H66.mat         \n",
            "  inflating: Healthy/H67.mat         \n",
            "  inflating: Healthy/H68.mat         \n",
            "  inflating: Healthy/H69.mat         \n",
            "  inflating: Healthy/H7.mat          \n",
            "  inflating: Healthy/H70.mat         \n",
            "  inflating: Healthy/H71.mat         \n",
            "  inflating: Healthy/H72.mat         \n",
            "  inflating: Healthy/H73.mat         \n",
            "  inflating: Healthy/H74.mat         \n",
            "  inflating: Healthy/H75.mat         \n",
            "  inflating: Healthy/H76.mat         \n",
            "  inflating: Healthy/H77.mat         \n",
            "  inflating: Healthy/H78.mat         \n",
            "  inflating: Healthy/H79.mat         \n",
            "  inflating: Healthy/H8.mat          \n",
            "  inflating: Healthy/H80.mat         \n",
            "  inflating: Healthy/H81.mat         \n",
            "  inflating: Healthy/H82.mat         \n",
            "  inflating: Healthy/H83.mat         \n",
            "  inflating: Healthy/H84.mat         \n",
            "  inflating: Healthy/H85.mat         \n",
            "  inflating: Healthy/H86.mat         \n",
            "  inflating: Healthy/H87.mat         \n",
            "  inflating: Healthy/H88.mat         \n",
            "  inflating: Healthy/H89.mat         \n",
            "  inflating: Healthy/H9.mat          \n",
            "  inflating: Healthy/H90.mat         \n",
            "  inflating: Healthy/H91.mat         \n",
            "  inflating: Healthy/H92.mat         \n",
            "  inflating: Healthy/H93.mat         \n",
            "  inflating: Healthy/H94.mat         \n",
            "  inflating: Healthy/H95.mat         \n",
            "  inflating: Healthy/H96.mat         \n",
            "  inflating: Healthy/H97.mat         \n",
            "  inflating: Healthy/H98.mat         \n",
            "  inflating: Healthy/H99.mat         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SRPgr4VaN9uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJg25RYJVtuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_iAlVFgVtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t0kfs7p1X60B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jO3o9078X6wN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2160623",
        "outputId": "dbff675c-2f0d-465f-caa0-ca5e53be8fa9"
      },
      "source": [
        "!pip install pyemd\n",
        "!pip install EMD-signal\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyemd\n",
            "  Downloading pyemd-1.0.0.tar.gz (87 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from pyemd) (2.0.2)\n",
            "Building wheels for collected packages: pyemd\n",
            "  Building wheel for pyemd (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyemd: filename=pyemd-1.0.0-cp312-cp312-linux_x86_64.whl size=746744 sha256=9268cf4f32c3ca767bfda6998e7322d3617b8dc4fbbd89b91cbd8dad30d9ec4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/7d/e0/84ae1a3c2e45898a01b400c288b56a601c03fd36f2a4d060bf\n",
            "Successfully built pyemd\n",
            "Installing collected packages: pyemd\n",
            "Successfully installed pyemd-1.0.0\n",
            "Collecting EMD-signal\n",
            "  Downloading EMD_signal-1.6.4-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.12/dist-packages (from EMD-signal) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.12/dist-packages (from EMD-signal) (1.16.1)\n",
            "Collecting pathos>=0.2.1 (from EMD-signal)\n",
            "  Downloading pathos-0.3.4-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from EMD-signal) (4.67.1)\n",
            "Collecting ppft>=1.7.7 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading ppft-1.7.7-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dill>=0.4.0 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pox>=0.3.6 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading pox-0.3.6-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting multiprocess>=0.70.18 (from pathos>=0.2.1->EMD-signal)\n",
            "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
            "Downloading EMD_signal-1.6.4-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pathos-0.3.4-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pox-0.3.6-py3-none-any.whl (29 kB)\n",
            "Downloading ppft-1.7.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ppft, pox, dill, multiprocess, pathos, EMD-signal\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires dill<0.3.9,>=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
            "datasets 4.0.0 requires multiprocess<0.70.17, but you have multiprocess 0.70.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed EMD-signal-1.6.4 dill-0.4.0 multiprocess-0.70.18 pathos-0.3.4 pox-0.3.6 ppft-1.7.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vRd99Oa3X6r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuXR_0MjjC2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python 3.10+\n",
        "# Target: Reproduce the paper's ~98% accuracy using the exact pipeline:\n",
        "# - Data windows: 5 seconds @ 1 kHz (5000 samples) [file:1]\n",
        "# - Tri-axial combine: S(t) = sqrt(x^2 + y^2 + z^2) then normalize by max amplitude [file:1]\n",
        "# - Denoising: EMD with 10 IMFs, discard IMF1 (noisiest), reconstruct IMF2..IMF10 + residue [file:1]\n",
        "# - Features: F4 hybrid = 13 features (7 time + 6 frequency) [file:1]\n",
        "# - Classifier: SVM quadratic kernel (poly degree=2) with standardization [file:1]\n",
        "# - Evaluation: 10-fold stratified cross-validation; report accuracy, sensitivity, specificity [file:1]\n",
        "#\n",
        "# Enhancements included:\n",
        "# - EMD stability: mirror padding and capped sifting iterations [file:1]\n",
        "# - Frequency features: zero-mean before FFT to stabilize moments [file:1]\n",
        "# - SVM tuning: small grid over C and gamma while keeping degree=2 [file:1]\n",
        "# - Confusion matrices: per-fold and overall aggregated CM across CV folds [file:1]\n",
        "#\n",
        "# Dependencies:\n",
        "# pip install numpy scipy scikit-learn PyEMD pandas tqdm\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import recall_score, make_scorer, confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ---------------- User paths ----------------\n",
        "Healthy_path = r'/content/Healthy'  # class 0 (Normal/Healthy) [file:1]\n",
        "Faulty_path  = r'/content/Faulty'   # class 1 (Faulty) [file:1]\n",
        "\n",
        "# ---------------- Sampling and windowing (Tip #1) ----------------\n",
        "FS = 1000.0              # Hz, per paper [file:1]\n",
        "WIN_SEC = 5.0            # seconds per segment [file:1]\n",
        "WIN_SAMPLES = int(FS * WIN_SEC)  # 5000 samples [file:1]\n",
        "\n",
        "# ---------------- EMD configuration (Tip #3 + stability) ----------------\n",
        "from PyEMD import EMD\n",
        "\n",
        "def emd_denoise(signal, max_imfs=10):\n",
        "    emd = EMD()\n",
        "    emd.FIXE = 0            # default stop when mean envelope ≈ 0 [file:1]\n",
        "    emd.MAX_ITERATION = 100 # cap sifting iterations for stability [file:1]\n",
        "    emd.spline_kind = \"cubic\"\n",
        "    # Mirror padding to mitigate edge effects [file:1]\n",
        "    pad = 50\n",
        "    s_pad = np.r_[signal[pad:0:-1], signal, signal[-2:-pad-2:-1]]\n",
        "    imfs = emd.emd(s_pad)\n",
        "    # Remove padding in IMFs\n",
        "    if imfs.ndim == 1:\n",
        "        imfs = imfs[None, :]\n",
        "    imfs = imfs[:, pad:pad+len(signal)]\n",
        "    # Enforce exactly 10 IMFs (truncate/pad) [file:1]\n",
        "    if imfs.shape[0] > max_imfs:\n",
        "        imfs = imfs[:max_imfs]\n",
        "    elif imfs.shape[0] < max_imfs:\n",
        "        imfs = np.vstack([imfs, np.zeros((max_imfs - imfs.shape[0], len(signal)))])\n",
        "    # Residue approximated as original minus sum(IMFs) [file:1]\n",
        "    recon_all = np.sum(imfs, axis=0)\n",
        "    residue = signal - recon_all\n",
        "    # Discard IMF1; reconstruct IMF2..IMF10 + residue [file:1]\n",
        "    recon = np.sum(imfs[1:], axis=0) + residue\n",
        "    return recon\n",
        "\n",
        "# ---------------- Feature extraction (F4) (Tip #4) ----------------\n",
        "# F4 = 13 features: Time (7): M, SD, SK, KR, PP, RMS, E\n",
        "#                   Freq (6): FM, FSD, FSK, FKR, BPWR, FMED [file:1]\n",
        "def features_time(sig):\n",
        "    M = np.mean(sig)\n",
        "    SD = np.std(sig, ddof=1)\n",
        "    SKw = skew(sig, bias=False)\n",
        "    KRt = kurtosis(sig, fisher=False, bias=False)  # kurtosis of normal ~ 3 [file:1]\n",
        "    PP = np.max(sig) - np.min(sig)\n",
        "    RMS = np.sqrt(np.mean(sig**2))\n",
        "    E = np.sum(sig**2)\n",
        "    return [M, SD, SKw, KRt, PP, RMS, E]\n",
        "\n",
        "def features_freq(sig, fs=FS):\n",
        "    sig_zm = sig - np.mean(sig)\n",
        "    X = np.abs(rfft(sig_zm))\n",
        "    freqs = rfftfreq(sig_zm.size, d=1.0/fs)\n",
        "    psd = X**2\n",
        "    N = sig_zm.size\n",
        "    power_sum = np.sum(psd) + 1e-12\n",
        "    FM = np.sum(freqs * psd) / power_sum\n",
        "    var_f = np.sum(((freqs - FM)**2) * psd) / power_sum\n",
        "    FSD = np.sqrt(max(var_f, 0.0))\n",
        "    p = psd / power_sum\n",
        "    centered = freqs - FM\n",
        "    m3 = np.sum((centered**3) * p)\n",
        "    m4 = np.sum((centered**4) * p)\n",
        "    FSK = m3 / (FSD**3 + 1e-12)\n",
        "    FKR = m4 / (FSD**4 + 1e-12)\n",
        "    BPWR_N = power_sum / N   # normalized band power (replaces BPWR) [file:1]\n",
        "    cdf = np.cumsum(p)\n",
        "    idx_med = np.searchsorted(cdf, 0.5)\n",
        "    FMED = freqs[min(idx_med, len(freqs)-1)]\n",
        "    return [FM, FSD, FSK, FKR, BPWR_N, FMED]\n",
        "\n",
        "def extract_F4(sig):\n",
        "    return np.array(features_time(sig) + features_freq(sig), dtype=float)\n",
        "\n",
        "# ---------------- Tri-axial combine + normalization (Tip #2) ----------------\n",
        "def combine_axes_normalize(x, y, z):\n",
        "    # S(t) = sqrt(x^2 + y^2 + z^2) [file:1]\n",
        "    s = np.sqrt(x**2 + y**2 + z**2)\n",
        "    # Normalize by max amplitude BEFORE EMD [file:1]\n",
        "    max_abs = np.max(np.abs(s))\n",
        "    if max_abs > 0:\n",
        "        s = s / max_abs\n",
        "    return s\n",
        "\n",
        "# ---------------- .mat parsing helpers ----------------\n",
        "# The dataset uses a single key 'H' with shape (5000, 3). [file:1]\n",
        "COMMON_AXIS_KEYS = [\n",
        "    ('x','y','z'),\n",
        "    ('X','Y','Z'),\n",
        "    ('ax','ay','az'),\n",
        "    ('AX','AY','AZ'),\n",
        "    ('ch1','ch2','ch3'),\n",
        "    ('CH1','CH2','CH3'),\n",
        "    ('vx','vy','vz'),\n",
        "    ('a_x','a_y','a_z'),\n",
        "]\n",
        "\n",
        "def _find_axes_in_mat(mat):\n",
        "    keys = set(mat.keys())\n",
        "    # Special-case: key 'H' with (N,3) => columns are x,y,z [file:1]\n",
        "    if 'H' in keys:\n",
        "        H = np.squeeze(np.array(mat['H'])).astype(float)\n",
        "        if isinstance(H, np.ndarray) and H.ndim == 2 and H.shape[1] == 3:\n",
        "            return H[:,0], H[:,1], H[:,2]\n",
        "    # Otherwise, try common flat key triplets\n",
        "    for kx,ky,kz in COMMON_AXIS_KEYS:\n",
        "        if kx in keys and ky in keys and kz in keys:\n",
        "            x = np.squeeze(mat[kx]).astype(float)\n",
        "            y = np.squeeze(mat[ky]).astype(float)\n",
        "            z = np.squeeze(mat[kz]).astype(float)\n",
        "            return x, y, z\n",
        "    # Fallback: auto-detect three equal-length 1D vectors\n",
        "    arrays = [np.squeeze(mat[k]) for k in keys if not k.startswith('__')]\n",
        "    vecs = [a for a in arrays if isinstance(a, np.ndarray) and a.ndim == 1]\n",
        "    if len(vecs) >= 3 and len(vecs[0]) == len(vecs[1]) == len(vecs[2]):\n",
        "        return vecs[0].astype(float), vecs[1].astype(float), vecs[2].astype(float)\n",
        "    raise ValueError(\"Tri-axial vectors not found (expected key 'H' with shape (N,3) or x/y/z style keys).\")\n",
        "\n",
        "# Enforce 5 s windows; split or pad as needed (Tip #1) [file:1]\n",
        "def _segment_or_trim(sig, target_len=WIN_SAMPLES):\n",
        "    n = len(sig)\n",
        "    if n == target_len:\n",
        "        return [sig]\n",
        "    if n < target_len:\n",
        "        out = np.zeros(target_len, dtype=float)\n",
        "        out[:n] = sig\n",
        "        return [out]\n",
        "    segments = []\n",
        "    start = 0\n",
        "    while start + target_len <= n:\n",
        "        segments.append(sig[start:start+target_len])\n",
        "        start += target_len\n",
        "    return segments\n",
        "\n",
        "def load_folder_mat(folder, label):\n",
        "    Xx_list, Xy_list, Xz_list, y_list = [], [], [], []\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.mat\")))\n",
        "    for f in tqdm(files, desc=f\"Loading {folder}\"):\n",
        "        mat = loadmat(f)\n",
        "        x, y, z = _find_axes_in_mat(mat)\n",
        "        x = np.ravel(x)\n",
        "        y = np.ravel(y)\n",
        "        z = np.ravel(z)\n",
        "        x_segs = _segment_or_trim(x, WIN_SAMPLES)\n",
        "        y_segs = _segment_or_trim(y, WIN_SAMPLES)\n",
        "        z_segs = _segment_or_trim(z, WIN_SAMPLES)\n",
        "        n_segs = min(len(x_segs), len(y_segs), len(z_segs))\n",
        "        for i in range(n_segs):\n",
        "            Xx_list.append(x_segs[i])\n",
        "            Xy_list.append(y_segs[i])\n",
        "            Xz_list.append(z_segs[i])\n",
        "            y_list.append(label)  # 0=Healthy, 1=Faulty [file:1]\n",
        "    return np.array(Xx_list), np.array(Xy_list), np.array(Xz_list), np.array(y_list, dtype=int)\n",
        "\n",
        "# ---------------- Metrics: specificity (Tip #7) ----------------\n",
        "def specificity_score(y_true, y_pred, pos_label=1):\n",
        "    # Specificity = TN / (TN + FP) = recall of the negative class (0 if pos_label=1) [file:1]\n",
        "    neg = 0 if pos_label == 1 else 1\n",
        "    return recall_score(y_true == neg, y_pred == neg)\n",
        "\n",
        "def make_specificity_scorer(pos_label=1):\n",
        "    return make_scorer(specificity_score, greater_is_better=True)\n",
        "\n",
        "# ---------------- Build feature matrix ----------------\n",
        "def build_dataset_features(Xx, Xy, Xz):\n",
        "    N = Xx.shape[0]\n",
        "    feats = np.zeros((N, 13), dtype=float)\n",
        "    for i in tqdm(range(N), desc=\"EMD+F4 features\"):\n",
        "        s = combine_axes_normalize(Xx[i], Xy[i], Xz[i])   # combine + normalize [file:1]\n",
        "        s_d = emd_denoise(s, max_imfs=10)                 # EMD denoise (drop IMF1 + residue) [file:1]\n",
        "        feats[i] = extract_F4(s_d)                        # 13 features (F4) [file:1]\n",
        "    cols = [\"M\",\"SD\",\"SK\",\"KR\",\"PP\",\"RMS\",\"E\",\"FM\",\"FSD\",\"FSK\",\"FKR\",\"BPWR_N\",\"FMED\"]\n",
        "    return pd.DataFrame(feats, columns=cols)\n",
        "\n",
        "# ---------------- SVM tuning and evaluation ----------------\n",
        "def tune_svm_quadratic(X_feats, y, random_state=42):\n",
        "    pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"svm\", SVC(kernel=\"poly\", degree=2, coef0=0.0, class_weight=\"balanced\"))\n",
        "    ])\n",
        "    param_grid = {\n",
        "        \"svm__C\":     [0.5, 1.0, 2.0],\n",
        "        \"svm__gamma\": [\"scale\", 0.1, 0.2],\n",
        "    }\n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
        "    gs = GridSearchCV(pipe, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
        "    gs.fit(X_feats, y)\n",
        "    print(\"Best params (balanced, 10-fold):\", gs.best_params_, \"Best CV acc:\", gs.best_score_)\n",
        "    return gs.best_estimator_\n",
        "\n",
        "def evaluate_with_confusion_matrix(best_model, X_feats, y, random_state=42):\n",
        "    # 10-fold stratified CV with per-fold and aggregated confusion matrices [file:1]\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=random_state)\n",
        "    accs, sens, specs = [], [], []\n",
        "    cm_total = np.zeros((2,2), dtype=int)\n",
        "    fold = 1\n",
        "    for train_idx, test_idx in skf.split(X_feats, y):\n",
        "        X_tr, X_te = X_feats[train_idx], X_feats[test_idx]\n",
        "        y_tr, y_te = y[train_idx], y[test_idx]\n",
        "        # Refit the provided best_model on each training fold for honest CV [file:1]\n",
        "        best_model.fit(X_tr, y_tr)\n",
        "        y_pred = best_model.predict(X_te)\n",
        "        # Metrics\n",
        "        accs.append(accuracy_score(y_te, y_pred))\n",
        "        sens.append(recall_score(y_te, y_pred, pos_label=1))   # sensitivity [file:1]\n",
        "        specs.append(specificity_score(y_te, y_pred, pos_label=1)) # specificity [file:1]\n",
        "        # Confusion matrix for this fold\n",
        "        cm = confusion_matrix(y_te, y_pred, labels=[0,1])\n",
        "        cm_total += cm\n",
        "        print(f\"Fold {fold} CM (rows=true [0,1], cols=pred [0,1]):\\n{cm}\")\n",
        "        fold += 1\n",
        "    print(\"Aggregated CM over 10 folds (rows=true [0,1], cols=pred [0,1]):\\n\", cm_total)\n",
        "    print({\n",
        "        \"accuracy_mean\": float(np.mean(accs)),\n",
        "        \"accuracy_std\": float(np.std(accs, ddof=1)),\n",
        "        \"sensitivity_mean\": float(np.mean(sens)),\n",
        "        \"specificity_mean\": float(np.mean(specs)),\n",
        "    })\n",
        "\n",
        "# ---------------- Main ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load Healthy (0) and Faulty (1) datasets [file:1]\n",
        "    Xx_h, Xy_h, Xz_h, y_h = load_folder_mat(Healthy_path, label=0)\n",
        "    Xx_f, Xy_f, Xz_f, y_f = load_folder_mat(Faulty_path,  label=1)\n",
        "\n",
        "    # Concatenate classes\n",
        "    Xx = np.vstack([Xx_h, Xx_f])\n",
        "    Xy = np.vstack([Xy_h, Xy_f])\n",
        "    Xz = np.vstack([Xz_h, Xz_f])\n",
        "    y  = np.concatenate([y_h, y_f])\n",
        "\n",
        "    # Sanity check: should be 220 segments with class counts ~[103,117] per paper [file:1]\n",
        "    print(\"Total segments:\", len(y), \"Class balance:\", np.bincount(y))\n",
        "\n",
        "    # Build features (F4) [file:1]\n",
        "    feats_df = build_dataset_features(Xx, Xy, Xz)\n",
        "    X_feats = feats_df.values\n",
        "\n",
        "    # Tune quadratic SVM (10-fold CV on full data to pick hyperparams) [file:1]\n",
        "    best_model = tune_svm_quadratic(X_feats, y, random_state=42)\n",
        "\n",
        "    # Final 10-fold evaluation with confusion matrices using the tuned model [file:1]\n",
        "    evaluate_with_confusion_matrix(best_model, X_feats, y, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjZsN0GhjCzq",
        "outputId": "d90fb489-fdc4-4a55-deea-6a9bbb224806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /content/Healthy: 100%|██████████| 103/103 [00:00<00:00, 969.35it/s]\n",
            "Loading /content/Faulty: 100%|██████████| 117/117 [00:00<00:00, 1119.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments: 220 Class balance: [103 117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EMD+F4 features: 100%|██████████| 220/220 [00:35<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (balanced, 10-fold): {'svm__C': 0.5, 'svm__gamma': 0.2} Best CV acc: 0.940909090909091\n",
            "Fold 1 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[11  0]\n",
            " [ 3  8]]\n",
            "Fold 2 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[11  0]\n",
            " [ 0 11]]\n",
            "Fold 3 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[11  0]\n",
            " [ 0 11]]\n",
            "Fold 4 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 2 10]]\n",
            "Fold 5 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 0 12]]\n",
            "Fold 6 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 0 12]]\n",
            "Fold 7 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 3  9]]\n",
            "Fold 8 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 1 11]]\n",
            "Fold 9 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[ 9  1]\n",
            " [ 0 12]]\n",
            "Fold 10 CM (rows=true [0,1], cols=pred [0,1]):\n",
            "[[10  0]\n",
            " [ 3  9]]\n",
            "Aggregated CM over 10 folds (rows=true [0,1], cols=pred [0,1]):\n",
            " [[102   1]\n",
            " [ 12 105]]\n",
            "{'accuracy_mean': 0.940909090909091, 'accuracy_std': 0.060795159538602664, 'sensitivity_mean': 0.8977272727272727, 'specificity_mean': 0.99}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_feats.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WapxXbk9owX5",
        "outputId": "f3972d12-2b88-4aa1-ff9d-e1f1cfab4ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(220, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Predict on the full dataset\n",
        "y_pred = best_model.predict(X_feats)\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(6,5))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Healthy\",\"Faulty\"], yticklabels=[\"Healthy\",\"Faulty\"])\n",
        "plt.ylabel(\"True label\")\n",
        "plt.xlabel(\"Predicted label\")\n",
        "plt.title(\"Confusion Matrix - Best Model\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "k8T7ul2SjCwP",
        "outputId": "d1397dd4-4616-4bf6-ad15-00211bc96768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s0HgdKiLjCs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F3XVWjvjCpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78i6XfZ4jCld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NqNl5mG2pED1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vW4DvvJEpEAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2P2WZA5CpD9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObAjP1okpDri"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pZj2GD7UpDn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O64ekyGtpDg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whJdustcpDdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clfHk1hvpDVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6WJriqixpDM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PSFzw-hRk1mi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated script: One-Class SVM trained on healthy data only\n",
        "# Python 3.10+\n",
        "# Dependencies: numpy scipy scikit-learn PyEMD pandas tqdm\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import recall_score, make_scorer, confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "# ---------------- User paths ----------------\n",
        "Healthy_path = r'/content/Healthy'  # class 0 (Normal/Healthy)\n",
        "Faulty_path  = r'/content/Faulty'   # class 1 (Faulty)\n",
        "\n",
        "# ---------------- Sampling and windowing ----------------\n",
        "FS = 1000.0\n",
        "WIN_SEC = 5.0\n",
        "WIN_SAMPLES = int(FS * WIN_SEC)  # 5000\n",
        "\n",
        "# ---------------- EMD configuration ----------------\n",
        "from PyEMD import EMD\n",
        "\n",
        "def emd_denoise(signal, max_imfs=10):\n",
        "    emd = EMD()\n",
        "    emd.FIXE = 0\n",
        "    emd.MAX_ITERATION = 100\n",
        "    emd.spline_kind = \"cubic\"\n",
        "    pad = 50\n",
        "    s_pad = np.r_[signal[pad:0:-1], signal, signal[-2:-pad-2:-1]]\n",
        "    imfs = emd.emd(s_pad)\n",
        "    if imfs.ndim == 1:\n",
        "        imfs = imfs[None, :]\n",
        "    imfs = imfs[:, pad:pad+len(signal)]\n",
        "    if imfs.shape[0] > max_imfs:\n",
        "        imfs = imfs[:max_imfs]\n",
        "    elif imfs.shape[0] < max_imfs:\n",
        "        imfs = np.vstack([imfs, np.zeros((max_imfs - imfs.shape[0], len(signal)))])\n",
        "    recon_all = np.sum(imfs, axis=0)\n",
        "    residue = signal - recon_all\n",
        "    recon = np.sum(imfs[1:], axis=0) + residue\n",
        "    return recon\n",
        "\n",
        "# ---------------- Feature extraction (F4) ----------------\n",
        "def features_time(sig):\n",
        "    M = np.mean(sig)\n",
        "    SD = np.std(sig, ddof=1)\n",
        "    SKw = skew(sig, bias=False)\n",
        "    KRt = kurtosis(sig, fisher=False, bias=False)\n",
        "    PP = np.max(sig) - np.min(sig)\n",
        "    RMS = np.sqrt(np.mean(sig**2))\n",
        "    E = np.sum(sig**2)\n",
        "    return [M, SD, SKw, KRt, PP, RMS, E]\n",
        "\n",
        "def features_freq(sig, fs=FS):\n",
        "    sig_zm = sig - np.mean(sig)\n",
        "    X = np.abs(rfft(sig_zm))\n",
        "    freqs = rfftfreq(sig_zm.size, d=1.0/fs)\n",
        "    psd = X**2\n",
        "    N = sig_zm.size\n",
        "    power_sum = np.sum(psd) + 1e-12\n",
        "    FM = np.sum(freqs * psd) / power_sum\n",
        "    var_f = np.sum(((freqs - FM)**2) * psd) / power_sum\n",
        "    FSD = np.sqrt(max(var_f, 0.0))\n",
        "    p = psd / power_sum\n",
        "    centered = freqs - FM\n",
        "    m3 = np.sum((centered**3) * p)\n",
        "    m4 = np.sum((centered**4) * p)\n",
        "    FSK = m3 / (FSD**3 + 1e-12)\n",
        "    FKR = m4 / (FSD**4 + 1e-12)\n",
        "    BPWR_N = power_sum / N\n",
        "    cdf = np.cumsum(p)\n",
        "    idx_med = np.searchsorted(cdf, 0.5)\n",
        "    FMED = freqs[min(idx_med, len(freqs)-1)]\n",
        "    return [FM, FSD, FSK, FKR, BPWR_N, FMED]\n",
        "\n",
        "def extract_F4(sig):\n",
        "    return np.array(features_time(sig) + features_freq(sig), dtype=float)\n",
        "\n",
        "# ---------------- Tri-axial combine + normalization ----------------\n",
        "def combine_axes_normalize(x, y, z):\n",
        "    s = np.sqrt(x**2 + y**2 + z**2)\n",
        "    max_abs = np.max(np.abs(s))\n",
        "    if max_abs > 0:\n",
        "        s = s / max_abs\n",
        "    return s\n",
        "\n",
        "# ---------------- .mat parsing helpers ----------------\n",
        "COMMON_AXIS_KEYS = [\n",
        "    ('x','y','z'),\n",
        "    ('X','Y','Z'),\n",
        "    ('ax','ay','az'),\n",
        "    ('AX','AY','AZ'),\n",
        "    ('ch1','ch2','ch3'),\n",
        "    ('CH1','CH2','CH3'),\n",
        "    ('vx','vy','vz'),\n",
        "    ('a_x','a_y','a_z'),\n",
        "]\n",
        "\n",
        "def _find_axes_in_mat(mat):\n",
        "    keys = set(mat.keys())\n",
        "    if 'H' in keys:\n",
        "        H = np.squeeze(np.array(mat['H'])).astype(float)\n",
        "        if isinstance(H, np.ndarray) and H.ndim == 2 and H.shape[1] == 3:\n",
        "            return H[:,0], H[:,1], H[:,2]\n",
        "    for kx,ky,kz in COMMON_AXIS_KEYS:\n",
        "        if kx in keys and ky in keys and kz in keys:\n",
        "            x = np.squeeze(mat[kx]).astype(float)\n",
        "            y = np.squeeze(mat[ky]).astype(float)\n",
        "            z = np.squeeze(mat[kz]).astype(float)\n",
        "            return x, y, z\n",
        "    arrays = [np.squeeze(mat[k]) for k in keys if not k.startswith('__')]\n",
        "    vecs = [a for a in arrays if isinstance(a, np.ndarray) and a.ndim == 1]\n",
        "    if len(vecs) >= 3 and len(vecs[0]) == len(vecs[1]) == len(vecs[2]):\n",
        "        return vecs[0].astype(float), vecs[1].astype(float), vecs[2].astype(float)\n",
        "    raise ValueError(\"Tri-axial vectors not found\")\n",
        "\n",
        "def _segment_or_trim(sig, target_len=WIN_SAMPLES):\n",
        "    n = len(sig)\n",
        "    if n == target_len:\n",
        "        return [sig]\n",
        "    if n < target_len:\n",
        "        out = np.zeros(target_len, dtype=float)\n",
        "        out[:n] = sig\n",
        "        return [out]\n",
        "    segments = []\n",
        "    start = 0\n",
        "    while start + target_len <= n:\n",
        "        segments.append(sig[start:start+target_len])\n",
        "        start += target_len\n",
        "    return segments\n",
        "\n",
        "def load_folder_mat(folder, label):\n",
        "    Xx_list, Xy_list, Xz_list, y_list = [], [], [], []\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.mat\")))\n",
        "    for f in tqdm(files, desc=f\"Loading {folder}\"):\n",
        "        mat = loadmat(f)\n",
        "        x, y, z = _find_axes_in_mat(mat)\n",
        "        x = np.ravel(x)\n",
        "        y = np.ravel(y)\n",
        "        z = np.ravel(z)\n",
        "        x_segs = _segment_or_trim(x, WIN_SAMPLES)\n",
        "        y_segs = _segment_or_trim(y, WIN_SAMPLES)\n",
        "        z_segs = _segment_or_trim(z, WIN_SAMPLES)\n",
        "        n_segs = min(len(x_segs), len(y_segs), len(z_segs))\n",
        "        for i in range(n_segs):\n",
        "            Xx_list.append(x_segs[i])\n",
        "            Xy_list.append(y_segs[i])\n",
        "            Xz_list.append(z_segs[i])\n",
        "            y_list.append(label)\n",
        "    return np.array(Xx_list), np.array(Xy_list), np.array(Xz_list), np.array(y_list, dtype=int)\n",
        "\n",
        "# ---------------- Metrics: specificity ----------------\n",
        "def specificity_score(y_true, y_pred, pos_label=1):\n",
        "    neg = 0 if pos_label == 1 else 1\n",
        "    return recall_score(y_true == neg, y_pred == neg)\n",
        "\n",
        "def make_specificity_scorer(pos_label=1):\n",
        "    return make_scorer(specificity_score, greater_is_better=True)\n",
        "\n",
        "# ---------------- Build feature matrix ----------------\n",
        "def build_dataset_features(Xx, Xy, Xz):\n",
        "    N = Xx.shape[0]\n",
        "    feats = np.zeros((N, 13), dtype=float)\n",
        "    for i in tqdm(range(N), desc=\"EMD+F4 features\"):\n",
        "        s = combine_axes_normalize(Xx[i], Xy[i], Xz[i])\n",
        "        s_d = emd_denoise(s, max_imfs=10)\n",
        "        feats[i] = extract_F4(s_d)\n",
        "    cols = [\"M\",\"SD\",\"SK\",\"KR\",\"PP\",\"RMS\",\"E\",\"FM\",\"FSD\",\"FSK\",\"FKR\",\"BPWR_N\",\"FMED\"]\n",
        "    return pd.DataFrame(feats, columns=cols)\n",
        "\n",
        "# ---------------- SVM tuning and evaluation (adapted to One-Class) ----------------\n",
        "\n",
        "\n",
        "def tune_svm_rbf(X_feats, y, random_state=42):\n",
        "    \"\"\"\n",
        "    Trains a OneClassSVM with RBF kernel using stratified k-fold CV on healthy-only samples.\n",
        "    Returns the final fitted pipeline on all healthy samples using best params from CV.\n",
        "    \"\"\"\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
        "\n",
        "    nu_list = [0.01, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 0.25]\n",
        "    gamma_list = [\"scale\", 0.01, 0.05, 0.1, 0.2, 0.5]\n",
        "\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    # Manual grid search\n",
        "    for nu in nu_list:\n",
        "        for gamma in gamma_list:\n",
        "            fold_scores = []\n",
        "            for train_idx, val_idx in skf.split(X_feats, y):\n",
        "                # Use only healthy samples for training\n",
        "                X_train_fold = X_feats[train_idx][y[train_idx] == 0]\n",
        "                X_val_fold = X_feats[val_idx]\n",
        "                y_val_fold = y[val_idx]\n",
        "\n",
        "                pipe = Pipeline([\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"ocsvm\", OneClassSVM(kernel=\"rbf\", gamma=gamma, nu=nu))\n",
        "                ])\n",
        "                pipe.fit(X_train_fold)\n",
        "                preds = pipe.predict(X_val_fold)\n",
        "                pred_labels = np.where(preds == 1, 0, 1)  # 0=healthy, 1=faulty\n",
        "                acc = accuracy_score(y_val_fold, pred_labels)\n",
        "                fold_scores.append(acc)\n",
        "\n",
        "            mean_score = np.mean(fold_scores)\n",
        "            if mean_score > best_score:\n",
        "                best_score = mean_score\n",
        "                best_params = {\"nu\": nu, \"gamma\": gamma}\n",
        "\n",
        "    print(\"Best params (OCSVM RBF, CV):\", best_params, \"Best CV acc:\", best_score)\n",
        "\n",
        "    # Refit final model on all healthy samples using best params\n",
        "    X_healthy = X_feats[y == 0]\n",
        "    final_pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ocsvm\", OneClassSVM(kernel=\"rbf\", **best_params))\n",
        "    ])\n",
        "    final_pipe.fit(X_healthy)\n",
        "    return final_pipe\n",
        "\n",
        "    # Final model on all healthy samples\n",
        "    X_healthy = X_feats[y == 0]\n",
        "    final_pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ocsvm\", OneClassSVM(kernel=\"rbf\", gamma=best_params[\"gamma\"], nu=best_params[\"nu\"]))\n",
        "    ])\n",
        "    final_pipe.fit(X_healthy)\n",
        "    return final_pipe\n",
        "\n",
        "\n",
        "def evaluate_with_confusion_matrix(model, X_feats, y, n_splits=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Quick evaluation of a pre-trained One-Class SVM on the full dataset.\n",
        "    Assumes model is already fitted on healthy data.\n",
        "    \"\"\"\n",
        "    # Predict: 1 = inlier (healthy), -1 = outlier (faulty)\n",
        "    preds_raw = model.predict(X_feats)\n",
        "    pred_labels = np.where(preds_raw == 1, 0, 1)  # map to 0=Healthy, 1=Faulty\n",
        "\n",
        "    # Confusion matrix and metrics\n",
        "    cm = confusion_matrix(y, pred_labels, labels=[0, 1])\n",
        "    acc = accuracy_score(y, pred_labels)\n",
        "    sens = recall_score(y, pred_labels, pos_label=1)  # faulty recall\n",
        "    spec = specificity_score(y, pred_labels, pos_label=1)  # healthy recall\n",
        "\n",
        "    print(\"Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\\n\", cm)\n",
        "    print({\n",
        "        \"accuracy\": float(acc),\n",
        "        \"sensitivity (recall for faulty class=1)\": float(sens),\n",
        "        \"specificity (recall for healthy class=0)\": float(spec),\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"accuracy\": acc,\n",
        "        \"sensitivity\": sens,\n",
        "        \"specificity\": spec,\n",
        "        \"pred_labels\": pred_labels\n",
        "    }\n",
        "# ---------------- Main ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load Healthy (0) and Faulty (1) datasets\n",
        "    Xx_h, Xy_h, Xz_h, y_h = load_folder_mat(Healthy_path, label=0)\n",
        "    Xx_f, Xy_f, Xz_f, y_f = load_folder_mat(Faulty_path,  label=1)\n",
        "\n",
        "    # Concatenate classes\n",
        "    Xx = np.vstack([Xx_h, Xx_f])\n",
        "    Xy = np.vstack([Xy_h, Xy_f])\n",
        "    Xz = np.vstack([Xz_h, Xz_f])\n",
        "    y  = np.concatenate([y_h, y_f])\n",
        "\n",
        "    # Sanity check\n",
        "    print(\"Total segments:\", len(y), \"Class balance:\", np.bincount(y))\n",
        "\n",
        "    # Build features (F4)\n",
        "    feats_df = build_dataset_features(Xx, Xy, Xz)\n",
        "    X_feats = feats_df.values\n",
        "\n",
        "    # Train one-class SVM on healthy-only features\n",
        "    best_model = tune_svm_quadratic(X_feats, y, random_state=42)\n",
        "\n",
        "    # Evaluate on full dataset (healthy + faulty) and print confusion matrix\n",
        "    results = evaluate_with_confusion_matrix(best_model, X_feats, y, random_state=42)\n",
        "\n",
        "    # Optionally: save model and scaler for deployment\n",
        "    # from joblib import dump\n",
        "    # dump(best_model, \"oneclass_ocsvm_pipeline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k_qVRJrk1ie",
        "outputId": "f6b88be6-ec34-49b7-956a-21bad141f243"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /content/Healthy: 100%|██████████| 103/103 [00:00<00:00, 798.94it/s]\n",
            "Loading /content/Faulty: 100%|██████████| 117/117 [00:00<00:00, 842.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments: 220 Class balance: [103 117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EMD+F4 features: 100%|██████████| 220/220 [00:39<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params (OCSVM, CV): {'nu': 0.01, 'gamma': 0.01} Best CV acc: 0.9181818181818182\n",
            "Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\n",
            " [[ 99   4]\n",
            " [ 10 107]]\n",
            "{'accuracy': 0.9363636363636364, 'sensitivity (recall for faulty class=1)': 0.9145299145299145, 'specificity (recall for healthy class=0)': 0.9611650485436893}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mIapJUjak1Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dJn3cUM4k1Tf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated script: One-Class SVM trained on healthy data only\n",
        "# Python 3.10+\n",
        "# Dependencies: numpy scipy scikit-learn PyEMD pandas tqdm\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import recall_score, make_scorer, confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "# ---------------- User paths ----------------\n",
        "Healthy_path = r'/content/Healthy'  # class 0 (Normal/Healthy)\n",
        "Faulty_path  = r'/content/Faulty'   # class 1 (Faulty)\n",
        "\n",
        "# ---------------- Sampling and windowing ----------------\n",
        "FS = 1000.0\n",
        "WIN_SEC = 5.0\n",
        "WIN_SAMPLES = int(FS * WIN_SEC)  # 5000\n",
        "\n",
        "# ---------------- EMD configuration ----------------\n",
        "from PyEMD import EMD\n",
        "\n",
        "def emd_denoise(signal, max_imfs=10):\n",
        "    emd = EMD()\n",
        "    emd.FIXE = 0\n",
        "    emd.MAX_ITERATION = 100\n",
        "    emd.spline_kind = \"cubic\"\n",
        "    pad = 50\n",
        "    s_pad = np.r_[signal[pad:0:-1], signal, signal[-2:-pad-2:-1]]\n",
        "    imfs = emd.emd(s_pad)\n",
        "    if imfs.ndim == 1:\n",
        "        imfs = imfs[None, :]\n",
        "    imfs = imfs[:, pad:pad+len(signal)]\n",
        "    if imfs.shape[0] > max_imfs:\n",
        "        imfs = imfs[:max_imfs]\n",
        "    elif imfs.shape[0] < max_imfs:\n",
        "        imfs = np.vstack([imfs, np.zeros((max_imfs - imfs.shape[0], len(signal)))])\n",
        "    recon_all = np.sum(imfs, axis=0)\n",
        "    residue = signal - recon_all\n",
        "    recon = np.sum(imfs[1:], axis=0) + residue\n",
        "    return recon\n",
        "\n",
        "# ---------------- Feature extraction (F4) ----------------\n",
        "def features_time(sig):\n",
        "    M = np.mean(sig)\n",
        "    SD = np.std(sig, ddof=1)\n",
        "    SKw = skew(sig, bias=False)\n",
        "    KRt = kurtosis(sig, fisher=False, bias=False)\n",
        "    PP = np.max(sig) - np.min(sig)\n",
        "    RMS = np.sqrt(np.mean(sig**2))\n",
        "    E = np.sum(sig**2)\n",
        "    return [M, SD, SKw, KRt, PP, RMS, E]\n",
        "\n",
        "def features_freq(sig, fs=FS):\n",
        "    sig_zm = sig - np.mean(sig)\n",
        "    X = np.abs(rfft(sig_zm))\n",
        "    freqs = rfftfreq(sig_zm.size, d=1.0/fs)\n",
        "    psd = X**2\n",
        "    N = sig_zm.size\n",
        "    power_sum = np.sum(psd) + 1e-12\n",
        "    FM = np.sum(freqs * psd) / power_sum\n",
        "    var_f = np.sum(((freqs - FM)**2) * psd) / power_sum\n",
        "    FSD = np.sqrt(max(var_f, 0.0))\n",
        "    p = psd / power_sum\n",
        "    centered = freqs - FM\n",
        "    m3 = np.sum((centered**3) * p)\n",
        "    m4 = np.sum((centered**4) * p)\n",
        "    FSK = m3 / (FSD**3 + 1e-12)\n",
        "    FKR = m4 / (FSD**4 + 1e-12)\n",
        "    BPWR_N = power_sum / N\n",
        "    cdf = np.cumsum(p)\n",
        "    idx_med = np.searchsorted(cdf, 0.5)\n",
        "    FMED = freqs[min(idx_med, len(freqs)-1)]\n",
        "    return [FM, FSD, FSK, FKR, BPWR_N, FMED]\n",
        "\n",
        "def extract_F4(sig):\n",
        "    return np.array(features_time(sig) + features_freq(sig), dtype=float)\n",
        "\n",
        "# ---------------- Tri-axial combine + normalization ----------------\n",
        "def combine_axes_normalize(x, y, z):\n",
        "    s = np.sqrt(x**2 + y**2 + z**2)\n",
        "    max_abs = np.max(np.abs(s))\n",
        "    if max_abs > 0:\n",
        "        s = s / max_abs\n",
        "    return s\n",
        "\n",
        "# ---------------- .mat parsing helpers ----------------\n",
        "COMMON_AXIS_KEYS = [\n",
        "    ('x','y','z'),\n",
        "    ('X','Y','Z'),\n",
        "    ('ax','ay','az'),\n",
        "    ('AX','AY','AZ'),\n",
        "    ('ch1','ch2','ch3'),\n",
        "    ('CH1','CH2','CH3'),\n",
        "    ('vx','vy','vz'),\n",
        "    ('a_x','a_y','a_z'),\n",
        "]\n",
        "\n",
        "def _find_axes_in_mat(mat):\n",
        "    keys = set(mat.keys())\n",
        "    if 'H' in keys:\n",
        "        H = np.squeeze(np.array(mat['H'])).astype(float)\n",
        "        if isinstance(H, np.ndarray) and H.ndim == 2 and H.shape[1] == 3:\n",
        "            return H[:,0], H[:,1], H[:,2]\n",
        "    for kx,ky,kz in COMMON_AXIS_KEYS:\n",
        "        if kx in keys and ky in keys and kz in keys:\n",
        "            x = np.squeeze(mat[kx]).astype(float)\n",
        "            y = np.squeeze(mat[ky]).astype(float)\n",
        "            z = np.squeeze(mat[kz]).astype(float)\n",
        "            return x, y, z\n",
        "    arrays = [np.squeeze(mat[k]) for k in keys if not k.startswith('__')]\n",
        "    vecs = [a for a in arrays if isinstance(a, np.ndarray) and a.ndim == 1]\n",
        "    if len(vecs) >= 3 and len(vecs[0]) == len(vecs[1]) == len(vecs[2]):\n",
        "        return vecs[0].astype(float), vecs[1].astype(float), vecs[2].astype(float)\n",
        "    raise ValueError(\"Tri-axial vectors not found\")\n",
        "\n",
        "def _segment_or_trim(sig, target_len=WIN_SAMPLES):\n",
        "    n = len(sig)\n",
        "    if n == target_len:\n",
        "        return [sig]\n",
        "    if n < target_len:\n",
        "        out = np.zeros(target_len, dtype=float)\n",
        "        out[:n] = sig\n",
        "        return [out]\n",
        "    segments = []\n",
        "    start = 0\n",
        "    while start + target_len <= n:\n",
        "        segments.append(sig[start:start+target_len])\n",
        "        start += target_len\n",
        "    return segments\n",
        "\n",
        "def load_folder_mat(folder, label):\n",
        "    Xx_list, Xy_list, Xz_list, y_list = [], [], [], []\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.mat\")))\n",
        "    for f in tqdm(files, desc=f\"Loading {folder}\"):\n",
        "        mat = loadmat(f)\n",
        "        x, y, z = _find_axes_in_mat(mat)\n",
        "        x = np.ravel(x)\n",
        "        y = np.ravel(y)\n",
        "        z = np.ravel(z)\n",
        "        x_segs = _segment_or_trim(x, WIN_SAMPLES)\n",
        "        y_segs = _segment_or_trim(y, WIN_SAMPLES)\n",
        "        z_segs = _segment_or_trim(z, WIN_SAMPLES)\n",
        "        n_segs = min(len(x_segs), len(y_segs), len(z_segs))\n",
        "        for i in range(n_segs):\n",
        "            Xx_list.append(x_segs[i])\n",
        "            Xy_list.append(y_segs[i])\n",
        "            Xz_list.append(z_segs[i])\n",
        "            y_list.append(label)\n",
        "    return np.array(Xx_list), np.array(Xy_list), np.array(Xz_list), np.array(y_list, dtype=int)\n",
        "\n",
        "# ---------------- Metrics: specificity ----------------\n",
        "def specificity_score(y_true, y_pred, pos_label=1):\n",
        "    neg = 0 if pos_label == 1 else 1\n",
        "    return recall_score(y_true == neg, y_pred == neg)\n",
        "\n",
        "def make_specificity_scorer(pos_label=1):\n",
        "    return make_scorer(specificity_score, greater_is_better=True)\n",
        "\n",
        "# ---------------- Build feature matrix ----------------\n",
        "def build_dataset_features(Xx, Xy, Xz):\n",
        "    N = Xx.shape[0]\n",
        "    feats = np.zeros((N, 13), dtype=float)\n",
        "    for i in tqdm(range(N), desc=\"EMD+F4 features\"):\n",
        "        s = combine_axes_normalize(Xx[i], Xy[i], Xz[i])\n",
        "        s_d = emd_denoise(s, max_imfs=10)\n",
        "        feats[i] = extract_F4(s_d)\n",
        "    cols = [\"M\",\"SD\",\"SK\",\"KR\",\"PP\",\"RMS\",\"E\",\"FM\",\"FSD\",\"FSK\",\"FKR\",\"BPWR_N\",\"FMED\"]\n",
        "    return pd.DataFrame(feats, columns=cols)\n",
        "\n",
        "# ---------------- SVM tuning and evaluation (adapted to One-Class) ----------------\n",
        "\n",
        "\n",
        "def tune_svm_rbf(X_feats_h, y_h, n_splits=5, random_state=42):\n",
        "    \"\"\"\n",
        "    Trains a OneClassSVM with RBF kernel using stratified k-fold CV on healthy-only samples.\n",
        "    Returns the final fitted pipeline on all healthy samples using best params from CV.\n",
        "\n",
        "    Parameters:\n",
        "    - X_feats_h: feature matrix for healthy samples only\n",
        "    - y_h: labels for healthy samples (all zeros)\n",
        "    - n_splits: number of CV folds\n",
        "    \"\"\"\n",
        "    print(f\"Starting One-Class SVM RBF tuning on {X_feats_h.shape[0]} healthy samples...\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    nu_list = [0.01, 0.03, 0.05, 0.08, 0.1, 0.15, 0.2, 0.25]\n",
        "    gamma_list = [\"scale\", 0.01, 0.05, 0.1, 0.2, 0.5]\n",
        "\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    total_combinations = len(nu_list) * len(gamma_list)\n",
        "    comb_counter = 1\n",
        "\n",
        "    # Manual grid search\n",
        "    for nu in nu_list:\n",
        "        for gamma in gamma_list:\n",
        "            print(f\"Testing combination {comb_counter}/{total_combinations}: nu={nu}, gamma={gamma}\")\n",
        "            comb_counter += 1\n",
        "            fold_scores = []\n",
        "\n",
        "            for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_feats_h, y_h), start=1):\n",
        "                X_train_fold = X_feats_h[train_idx]\n",
        "                X_val_fold = X_feats_h[val_idx]  # evaluation on healthy fold\n",
        "\n",
        "                pipe = Pipeline([\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"ocsvm\", OneClassSVM(kernel=\"rbf\", gamma=gamma, nu=nu))\n",
        "                ])\n",
        "                pipe.fit(X_train_fold)\n",
        "                preds = pipe.predict(X_val_fold)\n",
        "                pred_labels = np.where(preds == 1, 0, 1)  # 0=healthy, 1=faulty\n",
        "                acc = accuracy_score(y_h[val_idx], pred_labels)\n",
        "                fold_scores.append(acc)\n",
        "                print(f\"  Fold {fold_idx} accuracy: {acc:.4f}\")\n",
        "\n",
        "            mean_score = np.mean(fold_scores)\n",
        "            print(f\"  Mean CV accuracy for nu={nu}, gamma={gamma}: {mean_score:.4f}\\n\")\n",
        "\n",
        "            if mean_score > best_score:\n",
        "                best_score = mean_score\n",
        "                best_params = {\"nu\": nu, \"gamma\": gamma}\n",
        "\n",
        "    print(\"Best params (OCSVM RBF, CV):\", best_params, \"Best CV acc:\", best_score)\n",
        "\n",
        "    # Refit final model on all healthy samples using best params\n",
        "    final_pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ocsvm\", OneClassSVM(kernel=\"rbf\", **best_params))\n",
        "    ])\n",
        "    final_pipe.fit(X_feats_h)\n",
        "    print(\"Final One-Class SVM trained on all healthy samples.\\n\")\n",
        "\n",
        "    return final_pipe\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_with_confusion_matrix(model, X_feats, y, n_splits=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Quick evaluation of a pre-trained One-Class SVM on the full dataset.\n",
        "    Assumes model is already fitted on healthy data.\n",
        "    \"\"\"\n",
        "    # Predict: 1 = inlier (healthy), -1 = outlier (faulty)\n",
        "    preds_raw = model.predict(X_feats)\n",
        "    pred_labels = np.where(preds_raw == 1, 0, 1)  # map to 0=Healthy, 1=Faulty\n",
        "\n",
        "    # Confusion matrix and metrics\n",
        "    cm = confusion_matrix(y, pred_labels, labels=[0, 1])\n",
        "    acc = accuracy_score(y, pred_labels)\n",
        "    sens = recall_score(y, pred_labels, pos_label=1)  # faulty recall\n",
        "    spec = specificity_score(y, pred_labels, pos_label=1)  # healthy recall\n",
        "\n",
        "    print(\"Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\\n\", cm)\n",
        "    print({\n",
        "        \"accuracy\": float(acc),\n",
        "        \"sensitivity (recall for faulty class=1)\": float(sens),\n",
        "        \"specificity (recall for healthy class=0)\": float(spec),\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"accuracy\": acc,\n",
        "        \"sensitivity\": sens,\n",
        "        \"specificity\": spec,\n",
        "        \"pred_labels\": pred_labels\n",
        "    }\n",
        "# ---------------- Main ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load Healthy (0) and Faulty (1) datasets\n",
        "    Xx_h, Xy_h, Xz_h, y_h = load_folder_mat(Healthy_path, label=0)\n",
        "    Xx_f, Xy_f, Xz_f, y_f = load_folder_mat(Faulty_path,  label=1)\n",
        "\n",
        "    # Concatenate classes\n",
        "    Xx = np.vstack([Xx_h, Xx_f])\n",
        "    Xy = np.vstack([Xy_h, Xy_f])\n",
        "    Xz = np.vstack([Xz_h, Xz_f])\n",
        "    y  = np.concatenate([y_h, y_f])\n",
        "\n",
        "    # Sanity check\n",
        "    print(\"Total segments:\", len(y), \"Class balance:\", np.bincount(y))\n",
        "\n",
        "    # Build features (F4)\n",
        "    feats_df = build_dataset_features(Xx, Xy, Xz)\n",
        "    X_feats = feats_df.values\n",
        "\n",
        "    feats_df_h = build_dataset_features(Xx_h, Xy_h, Xz_h)\n",
        "    X_feats_h = feats_df_h.values\n",
        "\n",
        "    # Train one-class SVM on healthy-only features\n",
        "    best_model = tune_svm_rbf(X_feats_h, y_h, random_state=42)\n",
        "\n",
        "    # Evaluate on full dataset (healthy + faulty) and print confusion matrix\n",
        "    results = evaluate_with_confusion_matrix(best_model, X_feats, y, random_state=42)\n",
        "\n",
        "    # Optionally: save model and scaler for deployment\n",
        "    # from joblib import dump\n",
        "    # dump(best_model, \"oneclass_ocsvm_pipeline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i5qombdTlijN",
        "outputId": "496968b6-12d9-4aeb-d34b-cc521abbc4d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /content/Healthy: 100%|██████████| 103/103 [00:00<00:00, 516.15it/s]\n",
            "Loading /content/Faulty: 100%|██████████| 117/117 [00:00<00:00, 605.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments: 220 Class balance: [103 117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EMD+F4 features: 100%|██████████| 220/220 [00:44<00:00,  4.95it/s]\n",
            "EMD+F4 features: 100%|██████████| 103/103 [00:24<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting One-Class SVM RBF tuning on 103 healthy samples...\n",
            "Testing combination 1/48: nu=0.01, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.01, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 2/48: nu=0.01, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9500\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.01: 0.9229\n",
            "\n",
            "Testing combination 3/48: nu=0.01, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 4/48: nu=0.01, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 5/48: nu=0.01, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.4000\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.2: 0.4724\n",
            "\n",
            "Testing combination 6/48: nu=0.01, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.1429\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.5: 0.1252\n",
            "\n",
            "Testing combination 7/48: nu=0.03, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.03, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 8/48: nu=0.03, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9500\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.01: 0.9229\n",
            "\n",
            "Testing combination 9/48: nu=0.03, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 10/48: nu=0.03, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 11/48: nu=0.03, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 12/48: nu=0.03, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 13/48: nu=0.05, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.05, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 14/48: nu=0.05, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.01: 0.9129\n",
            "\n",
            "Testing combination 15/48: nu=0.05, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 16/48: nu=0.05, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 17/48: nu=0.05, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 18/48: nu=0.05, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 19/48: nu=0.08, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.08, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 20/48: nu=0.08, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.8500\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.01: 0.8838\n",
            "\n",
            "Testing combination 21/48: nu=0.08, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 22/48: nu=0.08, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 23/48: nu=0.08, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 24/48: nu=0.08, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 25/48: nu=0.1, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.1, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 26/48: nu=0.1, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9000\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.01: 0.8238\n",
            "\n",
            "Testing combination 27/48: nu=0.1, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.05: 0.7852\n",
            "\n",
            "Testing combination 28/48: nu=0.1, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 29/48: nu=0.1, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 30/48: nu=0.1, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 31/48: nu=0.15, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6500\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.15, gamma=scale: 0.7057\n",
            "\n",
            "Testing combination 32/48: nu=0.15, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.01: 0.7852\n",
            "\n",
            "Testing combination 33/48: nu=0.15, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.05: 0.7057\n",
            "\n",
            "Testing combination 34/48: nu=0.15, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.1: 0.6767\n",
            "\n",
            "Testing combination 35/48: nu=0.15, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 36/48: nu=0.15, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 37/48: nu=0.2, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.2, gamma=scale: 0.6767\n",
            "\n",
            "Testing combination 38/48: nu=0.2, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.01: 0.7557\n",
            "\n",
            "Testing combination 39/48: nu=0.2, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.05: 0.6862\n",
            "\n",
            "Testing combination 40/48: nu=0.2, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.1: 0.6667\n",
            "\n",
            "Testing combination 41/48: nu=0.2, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 42/48: nu=0.2, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 43/48: nu=0.25, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.25, gamma=scale: 0.6667\n",
            "\n",
            "Testing combination 44/48: nu=0.25, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.25, gamma=0.01: 0.7462\n",
            "\n",
            "Testing combination 45/48: nu=0.25, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.25, gamma=0.05: 0.6576\n",
            "\n",
            "Testing combination 46/48: nu=0.25, gamma=0.1\n",
            "  Fold 1 accuracy: 0.7143\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.5500\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.25, gamma=0.1: 0.6086\n",
            "\n",
            "Testing combination 47/48: nu=0.25, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.25, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 48/48: nu=0.25, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.25, gamma=0.5: 0.1157\n",
            "\n",
            "Best params (OCSVM RBF, CV): {'nu': 0.01, 'gamma': 0.01} Best CV acc: 0.9228571428571428\n",
            "Final One-Class SVM trained on all healthy samples.\n",
            "\n",
            "Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\n",
            " [[ 99   4]\n",
            " [ 10 107]]\n",
            "{'accuracy': 0.9363636363636364, 'sensitivity (recall for faulty class=1)': 0.9145299145299145, 'specificity (recall for healthy class=0)': 0.9611650485436893}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_fault_degree(model, X_feats):\n",
        "    \"\"\"\n",
        "    Compute continuous fault scores for each sample.\n",
        "\n",
        "    Parameters:\n",
        "    - model: fitted One-Class SVM pipeline\n",
        "    - X_feats: feature matrix (numpy array or pd.DataFrame)\n",
        "\n",
        "    Returns:\n",
        "    - fault_score_norm: normalized fault degree (0=healthy, 1=most faulty)\n",
        "    - pred_labels: binary predictions (0=healthy, 1=faulty)\n",
        "    - raw_scores: raw decision function output from OCSVM\n",
        "    \"\"\"\n",
        "    # Decision function: +ve inside healthy region, -ve outside\n",
        "    raw_scores = model.decision_function(X_feats).ravel()\n",
        "\n",
        "    # Flip sign: higher = more faulty\n",
        "    fault_score = -raw_scores\n",
        "\n",
        "    # Normalize to 0-1 for easy interpretation\n",
        "    fault_score_norm = (fault_score - fault_score.min()) / (fault_score.max() - fault_score.min() + 1e-12)\n",
        "\n",
        "    # Binary predictions\n",
        "    preds = model.predict(X_feats)\n",
        "    pred_labels = np.where(preds == 1, 0, 1)  # 0=healthy, 1=faulty\n",
        "\n",
        "    return fault_score_norm, pred_labels, raw_scores\n"
      ],
      "metadata": {
        "id": "Oz3LQklusagf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `best_model` is your fitted pipeline and `X_feats` is feature matrix\n",
        "fault_degree, labels, raw_scores = compute_fault_degree(best_model, X_feats)\n",
        "\n",
        "# Example: print top 10 most faulty segments\n",
        "top_faulty_idx = np.argsort(fault_degree)[-10:]\n",
        "for i in top_faulty_idx:\n",
        "    print(f\"Segment {i}: Fault degree={fault_degree[i]:.3f}, Label={labels[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTRlmvFCt9_u",
        "outputId": "65c9fbb2-fcd2-4454-ce23-16cd22691420"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segment 190: Fault degree=0.988, Label=1\n",
            "Segment 179: Fault degree=0.988, Label=1\n",
            "Segment 188: Fault degree=0.991, Label=1\n",
            "Segment 183: Fault degree=0.992, Label=1\n",
            "Segment 192: Fault degree=0.994, Label=1\n",
            "Segment 181: Fault degree=0.994, Label=1\n",
            "Segment 191: Fault degree=0.994, Label=1\n",
            "Segment 193: Fault degree=0.994, Label=1\n",
            "Segment 189: Fault degree=0.995, Label=1\n",
            "Segment 196: Fault degree=1.000, Label=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fault_degree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPXivoy_uA3G",
        "outputId": "555e3d74-fe52-450f-fa37-d2f6a0958b4e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10261222, 0.01854938, 0.07578934, 0.19540113, 0.10746858,\n",
              "       0.18735344, 0.1233037 , 0.12366975, 0.05378884, 0.04842201,\n",
              "       0.02104428, 0.08110527, 0.11280012, 0.19526317, 0.10897038,\n",
              "       0.19528145, 0.19540113, 0.08546586, 0.06430241, 0.08615764,\n",
              "       0.07245902, 0.1856921 , 0.04774001, 0.01614911, 0.03582968,\n",
              "       0.00950632, 0.06054344, 0.        , 0.03335787, 0.11409621,\n",
              "       0.0702271 , 0.18225238, 0.1076051 , 0.09097654, 0.0986241 ,\n",
              "       0.17482864, 0.10430401, 0.09093152, 0.05136493, 0.17791697,\n",
              "       0.07135931, 0.02366925, 0.07482838, 0.07713895, 0.04946404,\n",
              "       0.10273343, 0.0872524 , 0.06458132, 0.11173755, 0.01516033,\n",
              "       0.05559655, 0.12764347, 0.12868629, 0.1069698 , 0.10268091,\n",
              "       0.05987233, 0.01122064, 0.12059239, 0.10732838, 0.01935947,\n",
              "       0.14588577, 0.10856036, 0.10056098, 0.1186489 , 0.05335552,\n",
              "       0.11558455, 0.08582914, 0.04900826, 0.19547071, 0.13514258,\n",
              "       0.00537247, 0.09242136, 0.06442687, 0.05113072, 0.06464838,\n",
              "       0.06175808, 0.13807379, 0.11958932, 0.11512772, 0.15862768,\n",
              "       0.08230735, 0.08307566, 0.14633847, 0.16628659, 0.1692152 ,\n",
              "       0.10886328, 0.13991415, 0.12271065, 0.08635051, 0.0653724 ,\n",
              "       0.19556517, 0.11717485, 0.11992233, 0.095969  , 0.17765497,\n",
              "       0.14133898, 0.1952085 , 0.07023799, 0.14762699, 0.07305344,\n",
              "       0.10842344, 0.0967774 , 0.10628715, 0.90693103, 0.95358789,\n",
              "       0.19585049, 0.83917702, 0.38369153, 0.86262893, 0.16179758,\n",
              "       0.94935934, 0.47487951, 0.6416345 , 0.57008785, 0.56703246,\n",
              "       0.96746943, 0.45922384, 0.4108979 , 0.4323911 , 0.41265432,\n",
              "       0.1971777 , 0.90657272, 0.28408676, 0.19625104, 0.94436757,\n",
              "       0.79389864, 0.82017142, 0.90102915, 0.95680661, 0.95856092,\n",
              "       0.95396687, 0.96256509, 0.94052545, 0.96472495, 0.92410027,\n",
              "       0.95261295, 0.95469378, 0.9545085 , 0.94473638, 0.92393174,\n",
              "       0.90598989, 0.93757672, 0.93679885, 0.93813521, 0.96408427,\n",
              "       0.95474826, 0.96284253, 0.95601937, 0.93136482, 0.96995655,\n",
              "       0.94425091, 0.90451967, 0.89093791, 0.92912479, 0.95084231,\n",
              "       0.96729546, 0.97773895, 0.95508184, 0.96371672, 0.96872222,\n",
              "       0.96596122, 0.9672886 , 0.97844376, 0.96594965, 0.94968855,\n",
              "       0.94820272, 0.88991902, 0.9855569 , 0.98285568, 0.9757053 ,\n",
              "       0.9595859 , 0.91125601, 0.86892628, 0.85870496, 0.95143696,\n",
              "       0.96192074, 0.95389597, 0.97885533, 0.97147259, 0.98767751,\n",
              "       0.97397475, 0.99407681, 0.97254439, 0.99188573, 0.92392605,\n",
              "       0.92645637, 0.96025557, 0.95662176, 0.99055731, 0.99504344,\n",
              "       0.98753756, 0.99418444, 0.99404821, 0.99448299, 0.46275332,\n",
              "       0.37204074, 1.        , 0.88715589, 0.93937735, 0.96290808,\n",
              "       0.7037995 , 0.41257154, 0.69370471, 0.32242096, 0.4882775 ,\n",
              "       0.39404168, 0.13686616, 0.81000403, 0.18733775, 0.96398327,\n",
              "       0.05620485, 0.09385892, 0.03358064, 0.13954769, 0.31084445,\n",
              "       0.25641551, 0.21553233, 0.17494128, 0.10452202, 0.08451998])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from joblib import dump\n",
        "dump(best_model, \"oneclass_ocsvm_pipeline.joblib\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDWvrF36uRId",
        "outputId": "cf774015-7f9b-4f07-cdb1-4e1c8bd322d7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['oneclass_ocsvm_pipeline.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pm5AaCqWvXsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Save\n",
        "np.save(\"X_feats.npy\", X_feats)\n"
      ],
      "metadata": {
        "id": "FdN7n4MJvXol"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"X_feats.npy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FSolStnz3mjT",
        "outputId": "0c60e94c-9113-41fc-c22f-548a34b1ba47"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_278ad5a8-82af-4012-8bb7-eae4f7360005\", \"X_feats.npy\", 23008)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pDGfNlKZ3mfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNktlZre3mcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated script: One-Class SVM trained on healthy data only\n",
        "# Python 3.10+\n",
        "# Dependencies: numpy scipy scikit-learn PyEMD pandas tqdm\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "from scipy.stats import skew, kurtosis\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import recall_score, make_scorer, confusion_matrix, accuracy_score\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
        "import numpy as np\n",
        "# ---------------- User paths ----------------\n",
        "Healthy_path = r'/content/Healthy'  # class 0 (Normal/Healthy)\n",
        "Faulty_path  = r'/content/Faulty'   # class 1 (Faulty)\n",
        "\n",
        "# ---------------- Sampling and windowing ----------------\n",
        "FS = 1000.0\n",
        "WIN_SEC = 5.0\n",
        "WIN_SAMPLES = int(FS * WIN_SEC)  # 5000\n",
        "\n",
        "# ---------------- EMD configuration ----------------\n",
        "from PyEMD import EMD\n",
        "\n",
        "def emd_denoise(signal, max_imfs=10):\n",
        "    emd = EMD()\n",
        "    emd.FIXE = 0\n",
        "    emd.MAX_ITERATION = 100\n",
        "    emd.spline_kind = \"cubic\"\n",
        "    pad = 50\n",
        "    s_pad = np.r_[signal[pad:0:-1], signal, signal[-2:-pad-2:-1]]\n",
        "    imfs = emd.emd(s_pad)\n",
        "    if imfs.ndim == 1:\n",
        "        imfs = imfs[None, :]\n",
        "    imfs = imfs[:, pad:pad+len(signal)]\n",
        "    if imfs.shape[0] > max_imfs:\n",
        "        imfs = imfs[:max_imfs]\n",
        "    elif imfs.shape[0] < max_imfs:\n",
        "        imfs = np.vstack([imfs, np.zeros((max_imfs - imfs.shape[0], len(signal)))])\n",
        "    recon_all = np.sum(imfs, axis=0)\n",
        "    residue = signal - recon_all\n",
        "    recon = np.sum(imfs[1:], axis=0) + residue\n",
        "    return recon\n",
        "\n",
        "# ---------------- Feature extraction (F4) ----------------\n",
        "def features_time(sig):\n",
        "    M = np.mean(sig)\n",
        "    SD = np.std(sig, ddof=1)\n",
        "    SKw = skew(sig, bias=False)\n",
        "    KRt = kurtosis(sig, fisher=False, bias=False)\n",
        "    PP = np.max(sig) - np.min(sig)\n",
        "    RMS = np.sqrt(np.mean(sig**2))\n",
        "    E = np.sum(sig**2)\n",
        "    return [M, SD, SKw, KRt, PP, RMS, E]\n",
        "\n",
        "def features_freq(sig, fs=FS):\n",
        "    sig_zm = sig - np.mean(sig)\n",
        "    X = np.abs(rfft(sig_zm))\n",
        "    freqs = rfftfreq(sig_zm.size, d=1.0/fs)\n",
        "    psd = X**2\n",
        "    N = sig_zm.size\n",
        "    power_sum = np.sum(psd) + 1e-12\n",
        "    FM = np.sum(freqs * psd) / power_sum\n",
        "    var_f = np.sum(((freqs - FM)**2) * psd) / power_sum\n",
        "    FSD = np.sqrt(max(var_f, 0.0))\n",
        "    p = psd / power_sum\n",
        "    centered = freqs - FM\n",
        "    m3 = np.sum((centered**3) * p)\n",
        "    m4 = np.sum((centered**4) * p)\n",
        "    FSK = m3 / (FSD**3 + 1e-12)\n",
        "    FKR = m4 / (FSD**4 + 1e-12)\n",
        "    BPWR_N = power_sum / N\n",
        "    cdf = np.cumsum(p)\n",
        "    idx_med = np.searchsorted(cdf, 0.5)\n",
        "    FMED = freqs[min(idx_med, len(freqs)-1)]\n",
        "    return [FM, FSD, FSK, FKR, BPWR_N, FMED]\n",
        "\n",
        "def extract_F4(sig):\n",
        "    return np.array(features_time(sig) + features_freq(sig), dtype=float)\n",
        "\n",
        "# ---------------- Tri-axial combine + normalization ----------------\n",
        "def combine_axes_normalize(x, y, z):\n",
        "    s = np.sqrt(x**2 + y**2 + z**2)\n",
        "    max_abs = np.max(np.abs(s))\n",
        "    if max_abs > 0:\n",
        "        s = s / max_abs\n",
        "    return s\n",
        "\n",
        "# ---------------- .mat parsing helpers ----------------\n",
        "COMMON_AXIS_KEYS = [\n",
        "    ('x','y','z'),\n",
        "    ('X','Y','Z'),\n",
        "    ('ax','ay','az'),\n",
        "    ('AX','AY','AZ'),\n",
        "    ('ch1','ch2','ch3'),\n",
        "    ('CH1','CH2','CH3'),\n",
        "    ('vx','vy','vz'),\n",
        "    ('a_x','a_y','a_z'),\n",
        "]\n",
        "\n",
        "def _find_axes_in_mat(mat):\n",
        "    keys = set(mat.keys())\n",
        "    if 'H' in keys:\n",
        "        H = np.squeeze(np.array(mat['H'])).astype(float)\n",
        "        if isinstance(H, np.ndarray) and H.ndim == 2 and H.shape[1] == 3:\n",
        "            return H[:,0], H[:,1], H[:,2]\n",
        "    for kx,ky,kz in COMMON_AXIS_KEYS:\n",
        "        if kx in keys and ky in keys and kz in keys:\n",
        "            x = np.squeeze(mat[kx]).astype(float)\n",
        "            y = np.squeeze(mat[ky]).astype(float)\n",
        "            z = np.squeeze(mat[kz]).astype(float)\n",
        "            return x, y, z\n",
        "    arrays = [np.squeeze(mat[k]) for k in keys if not k.startswith('__')]\n",
        "    vecs = [a for a in arrays if isinstance(a, np.ndarray) and a.ndim == 1]\n",
        "    if len(vecs) >= 3 and len(vecs[0]) == len(vecs[1]) == len(vecs[2]):\n",
        "        return vecs[0].astype(float), vecs[1].astype(float), vecs[2].astype(float)\n",
        "    raise ValueError(\"Tri-axial vectors not found\")\n",
        "\n",
        "def _segment_or_trim(sig, target_len=WIN_SAMPLES):\n",
        "    n = len(sig)\n",
        "    if n == target_len:\n",
        "        return [sig]\n",
        "    if n < target_len:\n",
        "        out = np.zeros(target_len, dtype=float)\n",
        "        out[:n] = sig\n",
        "        return [out]\n",
        "    segments = []\n",
        "    start = 0\n",
        "    while start + target_len <= n:\n",
        "        segments.append(sig[start:start+target_len])\n",
        "        start += target_len\n",
        "    return segments\n",
        "\n",
        "def load_folder_mat(folder, label):\n",
        "    Xx_list, Xy_list, Xz_list, y_list = [], [], [], []\n",
        "    files = sorted(glob.glob(os.path.join(folder, \"*.mat\")))\n",
        "    for f in tqdm(files, desc=f\"Loading {folder}\"):\n",
        "        mat = loadmat(f)\n",
        "        x, y, z = _find_axes_in_mat(mat)\n",
        "        x = np.ravel(x)\n",
        "        y = np.ravel(y)\n",
        "        z = np.ravel(z)\n",
        "        x_segs = _segment_or_trim(x, WIN_SAMPLES)\n",
        "        y_segs = _segment_or_trim(y, WIN_SAMPLES)\n",
        "        z_segs = _segment_or_trim(z, WIN_SAMPLES)\n",
        "        n_segs = min(len(x_segs), len(y_segs), len(z_segs))\n",
        "        for i in range(n_segs):\n",
        "            Xx_list.append(x_segs[i])\n",
        "            Xy_list.append(y_segs[i])\n",
        "            Xz_list.append(z_segs[i])\n",
        "            y_list.append(label)\n",
        "    return np.array(Xx_list), np.array(Xy_list), np.array(Xz_list), np.array(y_list, dtype=int)\n",
        "\n",
        "# ---------------- Metrics: specificity ----------------\n",
        "def specificity_score(y_true, y_pred, pos_label=1):\n",
        "    neg = 0 if pos_label == 1 else 1\n",
        "    return recall_score(y_true == neg, y_pred == neg)\n",
        "\n",
        "def make_specificity_scorer(pos_label=1):\n",
        "    return make_scorer(specificity_score, greater_is_better=True)\n",
        "\n",
        "# ---------------- Build feature matrix ----------------\n",
        "def build_dataset_features(Xx, Xy, Xz):\n",
        "    N = Xx.shape[0]\n",
        "    feats = np.zeros((N, 13), dtype=float)\n",
        "    for i in tqdm(range(N), desc=\"EMD+F4 features\"):\n",
        "        s = combine_axes_normalize(Xx[i], Xy[i], Xz[i])\n",
        "        s_d = emd_denoise(s, max_imfs=10)\n",
        "        feats[i] = extract_F4(s_d)\n",
        "    cols = [\"M\",\"SD\",\"SK\",\"KR\",\"PP\",\"RMS\",\"E\",\"FM\",\"FSD\",\"FSK\",\"FKR\",\"BPWR_N\",\"FMED\"]\n",
        "    return pd.DataFrame(feats, columns=cols)\n",
        "\n",
        "# ---------------- SVM tuning and evaluation (adapted to One-Class) ----------------\n",
        "\n",
        "\n",
        "def tune_svm_rbf(X_feats_h, y_h, n_splits=5, random_state=42):\n",
        "    \"\"\"\n",
        "    Trains a OneClassSVM with RBF kernel using stratified k-fold CV on healthy-only samples.\n",
        "    Returns the final fitted pipeline on all healthy samples using best params from CV.\n",
        "\n",
        "    Parameters:\n",
        "    - X_feats_h: feature matrix for healthy samples only\n",
        "    - y_h: labels for healthy samples (all zeros)\n",
        "    - n_splits: number of CV folds\n",
        "    \"\"\"\n",
        "    print(f\"Starting One-Class SVM RBF tuning on {X_feats_h.shape[0]} healthy samples...\")\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    nu_list = [0.01, 0.03, 0.05, 0.08, 0.1, 0.12, 0.15, 0.18, 0.2]\n",
        "    gamma_list = [0.01, 0.03, 0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 'scale']\n",
        "\n",
        "\n",
        "    best_score = -1\n",
        "    best_params = None\n",
        "\n",
        "    total_combinations = len(nu_list) * len(gamma_list)\n",
        "    comb_counter = 1\n",
        "\n",
        "    # Manual grid search\n",
        "    for nu in nu_list:\n",
        "        for gamma in gamma_list:\n",
        "            print(f\"Testing combination {comb_counter}/{total_combinations}: nu={nu}, gamma={gamma}\")\n",
        "            comb_counter += 1\n",
        "            fold_scores = []\n",
        "\n",
        "            for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_feats_h, y_h), start=1):\n",
        "                X_train_fold = X_feats_h[train_idx]\n",
        "                X_val_fold = X_feats_h[val_idx]  # evaluation on healthy fold\n",
        "\n",
        "                pipe = Pipeline([\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"ocsvm\", OneClassSVM(kernel=\"rbf\", gamma=gamma, nu=nu))\n",
        "                ])\n",
        "                pipe.fit(X_train_fold)\n",
        "                preds = pipe.predict(X_val_fold)\n",
        "                pred_labels = np.where(preds == 1, 0, 1)  # 0=healthy, 1=faulty\n",
        "                acc = accuracy_score(y_h[val_idx], pred_labels)\n",
        "                fold_scores.append(acc)\n",
        "                print(f\"  Fold {fold_idx} accuracy: {acc:.4f}\")\n",
        "\n",
        "            mean_score = np.mean(fold_scores)\n",
        "            print(f\"  Mean CV accuracy for nu={nu}, gamma={gamma}: {mean_score:.4f}\\n\")\n",
        "\n",
        "            if mean_score > best_score:\n",
        "                best_score = mean_score\n",
        "                best_params = {\"nu\": nu, \"gamma\": gamma}\n",
        "\n",
        "    print(\"Best params (OCSVM RBF, CV):\", best_params, \"Best CV acc:\", best_score)\n",
        "\n",
        "    # Refit final model on all healthy samples using best params\n",
        "    final_pipe = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"ocsvm\", OneClassSVM(kernel=\"rbf\", **best_params))\n",
        "    ])\n",
        "    final_pipe.fit(X_feats_h)\n",
        "    print(\"Final One-Class SVM trained on all healthy samples.\\n\")\n",
        "\n",
        "    return final_pipe\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_with_confusion_matrix(model, X_feats, y, n_splits=10, random_state=42):\n",
        "    \"\"\"\n",
        "    Quick evaluation of a pre-trained One-Class SVM on the full dataset.\n",
        "    Assumes model is already fitted on healthy data.\n",
        "    \"\"\"\n",
        "    # Predict: 1 = inlier (healthy), -1 = outlier (faulty)\n",
        "    preds_raw = model.predict(X_feats)\n",
        "    pred_labels = np.where(preds_raw == 1, 0, 1)  # map to 0=Healthy, 1=Faulty\n",
        "\n",
        "    # Confusion matrix and metrics\n",
        "    cm = confusion_matrix(y, pred_labels, labels=[0, 1])\n",
        "    acc = accuracy_score(y, pred_labels)\n",
        "    sens = recall_score(y, pred_labels, pos_label=1)  # faulty recall\n",
        "    spec = specificity_score(y, pred_labels, pos_label=1)  # healthy recall\n",
        "\n",
        "    print(\"Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\\n\", cm)\n",
        "    print({\n",
        "        \"accuracy\": float(acc),\n",
        "        \"sensitivity (recall for faulty class=1)\": float(sens),\n",
        "        \"specificity (recall for healthy class=0)\": float(spec),\n",
        "    })\n",
        "\n",
        "    return {\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"accuracy\": acc,\n",
        "        \"sensitivity\": sens,\n",
        "        \"specificity\": spec,\n",
        "        \"pred_labels\": pred_labels\n",
        "    }\n",
        "# ---------------- Main ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Load Healthy (0) and Faulty (1) datasets\n",
        "    Xx_h, Xy_h, Xz_h, y_h = load_folder_mat(Healthy_path, label=0)\n",
        "    Xx_f, Xy_f, Xz_f, y_f = load_folder_mat(Faulty_path,  label=1)\n",
        "\n",
        "    # Concatenate classes\n",
        "    Xx = np.vstack([Xx_h, Xx_f])\n",
        "    Xy = np.vstack([Xy_h, Xy_f])\n",
        "    Xz = np.vstack([Xz_h, Xz_f])\n",
        "    y  = np.concatenate([y_h, y_f])\n",
        "\n",
        "    # Sanity check\n",
        "    print(\"Total segments:\", len(y), \"Class balance:\", np.bincount(y))\n",
        "\n",
        "    # Build features (F4)\n",
        "    feats_df = build_dataset_features(Xx, Xy, Xz)\n",
        "    X_feats = feats_df.values\n",
        "\n",
        "    feats_df_h = build_dataset_features(Xx_h, Xy_h, Xz_h)\n",
        "    X_feats_h = feats_df_h.values\n",
        "\n",
        "    # Train one-class SVM on healthy-only features\n",
        "    best_model = tune_svm_rbf(X_feats_h, y_h, random_state=42)\n",
        "\n",
        "    # Evaluate on full dataset (healthy + faulty) and print confusion matrix\n",
        "    results = evaluate_with_confusion_matrix(best_model, X_feats, y, random_state=42)\n",
        "\n",
        "    # Optionally: save model and scaler for deployment\n",
        "    # from joblib import dump\n",
        "    # dump(best_model, \"oneclass_ocsvm_pipeline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ntu6HNvXmS",
        "outputId": "30c985d4-3626-4e78-cc62-55762d0c76be"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading /content/Healthy: 100%|██████████| 103/103 [00:00<00:00, 576.10it/s]\n",
            "Loading /content/Faulty: 100%|██████████| 117/117 [00:00<00:00, 634.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total segments: 220 Class balance: [103 117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EMD+F4 features: 100%|██████████| 220/220 [00:41<00:00,  5.25it/s]\n",
            "EMD+F4 features: 100%|██████████| 103/103 [00:18<00:00,  5.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting One-Class SVM RBF tuning on 103 healthy samples...\n",
            "Testing combination 1/81: nu=0.01, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9500\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.01: 0.9229\n",
            "\n",
            "Testing combination 2/81: nu=0.01, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.8000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.03: 0.8538\n",
            "\n",
            "Testing combination 3/81: nu=0.01, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 4/81: nu=0.01, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 5/81: nu=0.01, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 6/81: nu=0.01, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.4000\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.2: 0.4724\n",
            "\n",
            "Testing combination 7/81: nu=0.01, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 8/81: nu=0.01, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.1429\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.01, gamma=0.5: 0.1252\n",
            "\n",
            "Testing combination 9/81: nu=0.01, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.01, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 10/81: nu=0.03, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9500\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.01: 0.9229\n",
            "\n",
            "Testing combination 11/81: nu=0.03, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.8000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.03: 0.8538\n",
            "\n",
            "Testing combination 12/81: nu=0.03, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 13/81: nu=0.03, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 14/81: nu=0.03, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.15: 0.5695\n",
            "\n",
            "Testing combination 15/81: nu=0.03, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 16/81: nu=0.03, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 17/81: nu=0.03, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.03, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 18/81: nu=0.03, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.03, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 19/81: nu=0.05, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.9000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.01: 0.9129\n",
            "\n",
            "Testing combination 20/81: nu=0.05, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.8000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.03: 0.8538\n",
            "\n",
            "Testing combination 21/81: nu=0.05, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 22/81: nu=0.05, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 23/81: nu=0.05, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 24/81: nu=0.05, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 25/81: nu=0.05, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 26/81: nu=0.05, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.05, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 27/81: nu=0.05, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.05, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 28/81: nu=0.08, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9500\n",
            "  Fold 5 accuracy: 0.8500\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.01: 0.8838\n",
            "\n",
            "Testing combination 29/81: nu=0.08, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.9048\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.03: 0.8338\n",
            "\n",
            "Testing combination 30/81: nu=0.08, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.7000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.05: 0.8052\n",
            "\n",
            "Testing combination 31/81: nu=0.08, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 32/81: nu=0.08, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 33/81: nu=0.08, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 34/81: nu=0.08, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 35/81: nu=0.08, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.08, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 36/81: nu=0.08, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.08, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 37/81: nu=0.1, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.9524\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9000\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.01: 0.8238\n",
            "\n",
            "Testing combination 38/81: nu=0.1, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.8571\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.03: 0.7943\n",
            "\n",
            "Testing combination 39/81: nu=0.1, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8500\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.05: 0.7852\n",
            "\n",
            "Testing combination 40/81: nu=0.1, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 41/81: nu=0.1, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 42/81: nu=0.1, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 43/81: nu=0.1, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 44/81: nu=0.1, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.1, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 45/81: nu=0.1, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.1, gamma=scale: 0.7357\n",
            "\n",
            "Testing combination 46/81: nu=0.12, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9000\n",
            "  Fold 5 accuracy: 0.6000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.01: 0.8048\n",
            "\n",
            "Testing combination 47/81: nu=0.12, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8571\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.03: 0.7648\n",
            "\n",
            "Testing combination 48/81: nu=0.12, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.7500\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.05: 0.7452\n",
            "\n",
            "Testing combination 49/81: nu=0.12, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.5000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.1: 0.6867\n",
            "\n",
            "Testing combination 50/81: nu=0.12, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 51/81: nu=0.12, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 52/81: nu=0.12, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 53/81: nu=0.12, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.12, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 54/81: nu=0.12, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6500\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.12, gamma=scale: 0.7257\n",
            "\n",
            "Testing combination 55/81: nu=0.15, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.9000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.01: 0.7852\n",
            "\n",
            "Testing combination 56/81: nu=0.15, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.03: 0.7452\n",
            "\n",
            "Testing combination 57/81: nu=0.15, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.05: 0.7057\n",
            "\n",
            "Testing combination 58/81: nu=0.15, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.1: 0.6767\n",
            "\n",
            "Testing combination 59/81: nu=0.15, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 60/81: nu=0.15, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 61/81: nu=0.15, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 62/81: nu=0.15, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.15, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 63/81: nu=0.15, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6500\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.15, gamma=scale: 0.7057\n",
            "\n",
            "Testing combination 64/81: nu=0.18, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.01: 0.7557\n",
            "\n",
            "Testing combination 65/81: nu=0.18, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.03: 0.7262\n",
            "\n",
            "Testing combination 66/81: nu=0.18, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.05: 0.7057\n",
            "\n",
            "Testing combination 67/81: nu=0.18, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.1: 0.6667\n",
            "\n",
            "Testing combination 68/81: nu=0.18, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 69/81: nu=0.18, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 70/81: nu=0.18, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 71/81: nu=0.18, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.18, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 72/81: nu=0.18, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.18, gamma=scale: 0.6862\n",
            "\n",
            "Testing combination 73/81: nu=0.2, gamma=0.01\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.8095\n",
            "  Fold 4 accuracy: 0.8000\n",
            "  Fold 5 accuracy: 0.5500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.01: 0.7557\n",
            "\n",
            "Testing combination 74/81: nu=0.2, gamma=0.03\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.7500\n",
            "  Fold 5 accuracy: 0.4500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.03: 0.7257\n",
            "\n",
            "Testing combination 75/81: nu=0.2, gamma=0.05\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.05: 0.6862\n",
            "\n",
            "Testing combination 76/81: nu=0.2, gamma=0.1\n",
            "  Fold 1 accuracy: 0.8095\n",
            "  Fold 2 accuracy: 0.7619\n",
            "  Fold 3 accuracy: 0.7619\n",
            "  Fold 4 accuracy: 0.6000\n",
            "  Fold 5 accuracy: 0.4000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.1: 0.6667\n",
            "\n",
            "Testing combination 77/81: nu=0.2, gamma=0.15\n",
            "  Fold 1 accuracy: 0.6190\n",
            "  Fold 2 accuracy: 0.6667\n",
            "  Fold 3 accuracy: 0.7143\n",
            "  Fold 4 accuracy: 0.5000\n",
            "  Fold 5 accuracy: 0.3000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.15: 0.5600\n",
            "\n",
            "Testing combination 78/81: nu=0.2, gamma=0.2\n",
            "  Fold 1 accuracy: 0.5714\n",
            "  Fold 2 accuracy: 0.5238\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.3500\n",
            "  Fold 5 accuracy: 0.2000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.2: 0.4624\n",
            "\n",
            "Testing combination 79/81: nu=0.2, gamma=0.3\n",
            "  Fold 1 accuracy: 0.3810\n",
            "  Fold 2 accuracy: 0.2381\n",
            "  Fold 3 accuracy: 0.3333\n",
            "  Fold 4 accuracy: 0.3000\n",
            "  Fold 5 accuracy: 0.1000\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.3: 0.2705\n",
            "\n",
            "Testing combination 80/81: nu=0.2, gamma=0.5\n",
            "  Fold 1 accuracy: 0.1429\n",
            "  Fold 2 accuracy: 0.1905\n",
            "  Fold 3 accuracy: 0.0952\n",
            "  Fold 4 accuracy: 0.1000\n",
            "  Fold 5 accuracy: 0.0500\n",
            "  Mean CV accuracy for nu=0.2, gamma=0.5: 0.1157\n",
            "\n",
            "Testing combination 81/81: nu=0.2, gamma=scale\n",
            "  Fold 1 accuracy: 0.8571\n",
            "  Fold 2 accuracy: 0.8095\n",
            "  Fold 3 accuracy: 0.6667\n",
            "  Fold 4 accuracy: 0.7000\n",
            "  Fold 5 accuracy: 0.3500\n",
            "  Mean CV accuracy for nu=0.2, gamma=scale: 0.6767\n",
            "\n",
            "Best params (OCSVM RBF, CV): {'nu': 0.01, 'gamma': 0.01} Best CV acc: 0.9228571428571428\n",
            "Final One-Class SVM trained on all healthy samples.\n",
            "\n",
            "Confusion Matrix (rows=true [0,1], cols=pred [0,1]):\n",
            " [[ 99   4]\n",
            " [ 10 107]]\n",
            "{'accuracy': 0.9363636363636364, 'sensitivity (recall for faulty class=1)': 0.9145299145299145, 'specificity (recall for healthy class=0)': 0.9611650485436893}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8I0gTMwvXjr",
        "outputId": "0c3d2a2e-33bd-41e5-d504-153062c73e4b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v35jREQlvXgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}